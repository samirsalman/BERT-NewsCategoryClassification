{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/news-category-dataset/News_Category_Dataset_v2.json\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# The task\n\nText classification datasets are used to categorize natural language texts according to content. For example, think **classifying news articles by topic**, or classifying book reviews based on a positive or negative response. Text classification is also helpful for language detection, organizing customer feedback, and fraud detection.\n\n**Category classification**, for news, is a text classification problem. The goal is to assign one category to a news article.\n\n![task](https://miro.medium.com/max/700/1*HgXA9v1EsqlrRDaC_iORhQ.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import nn\nimport pandas as pd\nimport numpy as np\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nimport seaborn as sns","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the data"},{"metadata":{},"cell_type":"markdown","source":"Data is an json file, each object has 6 columns. We can read the file with pandas and create its DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_json(\"../input/news-category-dataset/News_Category_Dataset_v2.json\", lines=True)\ndata.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"        category                                           headline  \\\n0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n\n           authors                                               link  \\\n0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n\n                                   short_description       date  \n0  She left her husband. He killed their children... 2018-05-26  \n1                           Of course it has a song. 2018-05-26  \n2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n4  The \"Dietland\" actress said using the bags is ... 2018-05-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>headline</th>\n      <th>authors</th>\n      <th>link</th>\n      <th>short_description</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CRIME</td>\n      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n      <td>Melissa Jeltsen</td>\n      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n      <td>She left her husband. He killed their children...</td>\n      <td>2018-05-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTERTAINMENT</td>\n      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n      <td>Andy McDonald</td>\n      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n      <td>Of course it has a song.</td>\n      <td>2018-05-26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ENTERTAINMENT</td>\n      <td>Hugh Grant Marries For The First Time At Age 57</td>\n      <td>Ron Dicker</td>\n      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n      <td>2018-05-26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ENTERTAINMENT</td>\n      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n      <td>Ron Dicker</td>\n      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n      <td>The actor gives Dems an ass-kicking for not fi...</td>\n      <td>2018-05-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTERTAINMENT</td>\n      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n      <td>Ron Dicker</td>\n      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n      <td>The \"Dietland\" actress said using the bags is ...</td>\n      <td>2018-05-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Remove columns that we can ignore\n\nFor our purpose we can ignore columns like authors or link. We can also define a new column named \"total_text\" that represents the concatenation between headline and short_description fields."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(data):\n    data[\"total_text\"] = data[\"headline\"] + \"\\n\" + data[\"short_description\"]\n    data.drop([\"authors\", \"link\", \"date\", \"headline\", \"short_description\"], axis=1, inplace=True)\n    return data","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = preprocess_data(data)\ndata.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"        category                                         total_text\n0          CRIME  There Were 2 Mass Shootings In Texas Last Week...\n1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...\n2  ENTERTAINMENT  Hugh Grant Marries For The First Time At Age 5...\n3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>total_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CRIME</td>\n      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENTERTAINMENT</td>\n      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ENTERTAINMENT</td>\n      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ENTERTAINMENT</td>\n      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENTERTAINMENT</td>\n      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.values[0]","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array(['CRIME',\n       'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV\\nShe left her husband. He killed their children. Just another day in America.'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Categories distribution"},{"metadata":{},"cell_type":"markdown","source":"We can list all category classes and show their distribution over the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(data[\"category\"].unique()))\nprint(data[\"category\"].unique())\nsns.countplot(data[\"category\"])","execution_count":26,"outputs":[{"output_type":"stream","text":"[ 9  8 15  4 35 34 31  7 36 32  2 13 25  0 28  1 38 20 39 12  3 24 10 33\n 14 37 11 30 29 26 23 27  6 18  5 22 16 40 19 17 21]\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  FutureWarning\n","name":"stderr"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"<AxesSubplot:xlabel='category', ylabel='count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## Change target values \n\nWe convert string classes to integer classes for the training step"},{"metadata":{"trusted":true},"cell_type":"code","source":"c = list(data[\"category\"].unique())\n\ndef sparse_categories(category):\n    return c.index(category)\n\ndata[\"category\"] = data[\"category\"].apply(sparse_categories)\ndata.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"   category                                         total_text\n0         0  There Were 2 Mass Shootings In Texas Last Week...\n1         1  Will Smith Joins Diplo And Nicky Jam For The 2...\n2         1  Hugh Grant Marries For The First Time At Age 5...\n3         1  Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n4         1  Julianna Margulies Uses Donald Trump Poop Bags...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>total_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Attention is All you Need\n\n![huggingface](https://huggingface.co/front/assets/huggingface_logo.svg)\n\nNow we can start the hot step. We install the transformers library (https://huggingface.co/transformers/). This famous library contains all transformer-based architecture implementations like BERT, BORT ecc...\n\nFor this task we use Small-Bert Model, a transformer based language model developed by Google, it represents the SOTA in a lot of NLP tasks. You can find more information at this link (https://huggingface.co/google/bert_uncased_L-4_H-512_A-8)."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":10,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.2.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.8)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\nRequirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.9.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.55.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.11.13)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.2)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")\n\nbert = AutoModel.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/383 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"634e2341cf7c48a2a918f18ee1236451"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211458a5f3484f038677543d437337a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/116M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf549b15369f4e7e965d20b0c21d5dd0"}},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Train, Test and Validation Sets\n\nNow we split dataset in three subset in order to create train, test and validation set.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffling the data\ndata = shuffle(data)\n\n# splitting data in train and val\ntrain_X, val_X, train_Y, val_Y = train_test_split(data.drop(\"category\", axis=1), data[\"category\"], test_size = 0.3)\n\n# splitting data in train and test\ntrain_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size = 0.2)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.sample(3)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                                               total_text\n177999  What's Your Strategy for Happiness?\\nYes, we a...\n31018   The Big Moves This Past Year In The Fight Agai...\n7089    The Cast Of ‘Incredibles 2’ Is Incredibly Good...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>177999</th>\n      <td>What's Your Strategy for Happiness?\\nYes, we a...</td>\n    </tr>\n    <tr>\n      <th>31018</th>\n      <td>The Big Moves This Past Year In The Fight Agai...</td>\n    </tr>\n    <tr>\n      <th>7089</th>\n      <td>The Cast Of ‘Incredibles 2’ Is Incredibly Good...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Dataset Object (PyTorch)\n\nhttps://pytorch.org/docs/stable/data.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TextDataset(Dataset):\n  def __init__(self, ids, texts, targets, tokenizer, max_len):\n    self.ids = ids\n    self.texts = texts\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n\n  def __getitem__(self, idx):\n    id = self.ids[idx]\n    text = self.texts[idx]\n    label = self.targets[idx]\n\n    encoding = self.tokenizer.encode_plus(\n      text,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      padding='max_length',\n      return_attention_mask=True,\n      truncation=True,\n      return_tensors='pt',\n    )\n\n    return {\n      'id': torch.tensor(id, dtype=torch.long),\n      'text': text,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'],\n      'label': torch.tensor(label, dtype=torch.int)\n    }\n\n  def __len__(self):\n    return len(self.texts)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 128\nBATCH_SIZE = 32\nTEST_BATCH_SIZE = 128\n\n\ntrain_dataset = TextDataset(\n  texts=train_X.total_text.to_numpy(),\n  targets=train_Y.to_numpy(),\n  ids=train_X.index.to_numpy(),\n  tokenizer=tokenizer,\n  max_len=MAX_LEN\n)\n\nval_dataset = TextDataset(\n  texts=val_X.total_text.to_numpy(),\n  targets=val_Y.to_numpy(),\n  ids=val_X.index.to_numpy(),\n  tokenizer=tokenizer,\n  max_len=MAX_LEN\n)\n\ntest_dataset = TextDataset(\n  texts=test_X.total_text.to_numpy(),\n  targets=test_Y.to_numpy(),\n  ids=test_X.index.to_numpy(),\n  tokenizer=tokenizer,\n  max_len=MAX_LEN\n)\n\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader =  DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=True)\nval_dataloader =  DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=True)\ntest_dataloader =  DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, num_workers=0, shuffle=True)","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classifier Model\n\n![classifier](https://miro.medium.com/max/1972/1*84bxdoawb55WogfXSV2rUQ.png)\n\nOur Text Classifier Model has the following architecture:\n\n* Bert Encoding Layer\n* Dropout Layer (default 0.3)\n* Feed-Forward Net for Output Layer (num of classes)\n\n**We don't apply softmax function on the output because in PyTorch the softmax is computed from the CrossEntropy Loss function.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TextClassifier(nn.Module):\n  def __init__(self, n_classes, bert_model, dropout=0.3):\n    super(TextClassifier, self).__init__()\n    self.bert = bert_model\n    self.drop = nn.Dropout(dropout)\n    self.out = nn.Linear(bert_model.config.hidden_size, n_classes)\n\n  def forward(self, input_ids, attention_mask):\n    pooled_output = self.bert(\n      input_ids=input_ids,\n      attention_mask = attention_mask\n    )\n    \n    output = self.drop(pooled_output[0][:, 0, :])\n    return self.out(output)\n\n  def save_pretrained(self, path):\n    self.bert.save_pretrained(path)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n\ndef eval_model(model, data_loader, loss_fn, device):\n  model = model.eval()\n  losses = []\n  predictions = []\n  all_predictions , true_labels, ids = [], [], []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    \n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      labels = d[\"label\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n      )\n      _, preds = torch.max(outputs, dim=1)\n      loss = loss_fn(outputs, labels.long())\n      losses.append(loss.item())\n      correct_predictions += torch.sum(preds == labels)\n      all_predictions.append(preds.cpu().data)\n      true_labels.append(labels.cpu().data) \n      ids.append(d[\"id\"].cpu().data)\n  \n  all_predictions = np.concatenate(all_predictions, axis=0)\n  true_labels = np.concatenate(true_labels, axis=0)\n  predictions = {\"id\":ids,\"preds\":all_predictions,\"exact\":true_labels}\n\n  \n  f1 = f1_score(true_labels, all_predictions, np.unique(all_predictions),average=\"macro\")\n  precision = precision_score(true_labels, all_predictions,labels=np.unique(all_predictions) ,average=\"macro\")\n  recall = recall_score(true_labels, all_predictions, labels=np.unique(all_predictions),average=\"macro\")\n  accuracy = accuracy_score(true_labels,all_predictions)\n\n  \n  \n  return accuracy, f1","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train function "},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(\n  model,\n  epochs,\n  train_data_loader,\n  val_data_loader,\n  loss_fn,\n  optimizer,\n  device,\n  scheduler):\n\n  model = model.train()\n\n  for e in range(epochs):\n    all_predictions , true_labels = [], []\n    correct_predictions = 0\n    losses = []\n\n    for d in tqdm(train_data_loader):\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      labels = d[\"label\"].to(device)\n      \n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n      )\n      _, preds = torch.max(outputs, dim=1)\n      loss = loss_fn(outputs, labels.long())\n\n      all_predictions.append(preds.cpu().data)\n      true_labels.append(labels.cpu().data) \n\n      correct_predictions += torch.sum(preds == labels)\n      losses.append(loss.item())\n      loss.backward()\n        \n      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n      \n      optimizer.step()\n      scheduler.step()\n      optimizer.zero_grad()\n\n    all_predictions = np.concatenate(all_predictions, axis=0)\n    true_labels = np.concatenate(true_labels, axis=0)\n    f1 = f1_score(true_labels, all_predictions,labels=np.unique(all_predictions),average=\"macro\")\n    precision = precision_score(true_labels, all_predictions,labels=np.unique(all_predictions) ,average=\"macro\")\n    recall = recall_score(true_labels, all_predictions, labels=np.unique(all_predictions),average=\"macro\")\n    accuracy = accuracy_score(true_labels,all_predictions)\n    print(f\"Epoch: {e + 1} Accuracy: {accuracy} F1: {f1}\" )\n\n    val_acc, val_f1 = eval_model(model, val_dataloader, loss_fn, device)\n    print(f\"Validation Accuracy: {val_acc} F1: {val_f1}\" )\n\n  return accuracy","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model instantiation\n\nNow we can instantiate our classifier and set-up the loss function, the optimizer and the scheduler (https://huggingface.co/transformers/main_classes/optimizer_schedules.html). We choose AdamW optimizer with a linear schedule with warmup and the CrossEntropyLoss."},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n\nmodel = TextClassifier(len(c), bert, 0.4) \nmodel = model.to(device)\nEPOCHS = 5\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\ntotal_steps = len(train_dataloader) * EPOCHS\nwarmup_step = int(len(train_dataloader)/2) \n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=warmup_step,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss().to(device)","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Now we can finnaly train our model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train(model=model, epochs=EPOCHS, train_data_loader=train_dataloader, val_data_loader=val_dataloader, \n      loss_fn=loss_fn, optimizer=optimizer, device=device, scheduler=scheduler)","execution_count":21,"outputs":[{"output_type":"stream","text":"100%|██████████| 3515/3515 [05:27<00:00, 10.75it/s]\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 1 Accuracy: 0.48248975346070755 F1: 0.30785582990533494\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n  0%|          | 2/3515 [00:00<05:23, 10.84it/s]","name":"stderr"},{"output_type":"stream","text":"Validation Accuracy: 0.6383098778544876 F1: 0.4926550675729907\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 3515/3515 [05:21<00:00, 10.92it/s]\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 2 Accuracy: 0.6775785271655539 F1: 0.5579582598047582\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n  0%|          | 2/3515 [00:00<05:27, 10.74it/s]","name":"stderr"},{"output_type":"stream","text":"Validation Accuracy: 0.6699747742963357 F1: 0.5597258339356919\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 3515/3515 [05:23<00:00, 10.87it/s]\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 3 Accuracy: 0.7468815846795345 F1: 0.6541604993303338\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n  0%|          | 2/3515 [00:00<05:25, 10.79it/s]","name":"stderr"},{"output_type":"stream","text":"Validation Accuracy: 0.6788369622942113 F1: 0.5748889103137221\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 3515/3515 [05:22<00:00, 10.89it/s]\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 4 Accuracy: 0.8082985854885888 F1: 0.735314782221856\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n  0%|          | 2/3515 [00:00<05:24, 10.82it/s]","name":"stderr"},{"output_type":"stream","text":"Validation Accuracy: 0.6787207912904939 F1: 0.5780197444803444\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 3515/3515 [05:21<00:00, 10.92it/s]\n","name":"stderr"},{"output_type":"stream","text":"Epoch: 5 Accuracy: 0.8541835219644905 F1: 0.795723930618233\nValidation Accuracy: 0.6755011949017525 F1: 0.5761567176370787\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n","name":"stderr"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"0.8541835219644905"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate the model on test set\n\nMeasure Accuracy and F1-measure over the test-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_acc, test_f1 = eval_model(model, test_dataloader, loss_fn, device)","execution_count":22,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_acc, test_f1)","execution_count":23,"outputs":[{"output_type":"stream","text":"0.6688833570412518 0.5674802453837637\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}